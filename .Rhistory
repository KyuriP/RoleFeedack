intersection / union
})
mean(similarities, na.rm = TRUE)
}
calculate_jaccard_similarity(cycles[[2]])
cycles[[2]]
str(cycles[[2]])
c <- list(
c(1, 2, 3),
c(2, 3, 4),
c(3, 4, 5)
)
calculate_jaccard_similarity(c)
rlang::last_trace()
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
if (length(cycles) <= 1) {
return(NA) # Return NA if there are 0 or 1 cycles
}
combinations <- combn(seq_along(cycles), 2, simplify = FALSE)
similarities <- map_dbl(combinations, ~ {
i <- .x[1]
j <- .x[2]
intersection <- length(intersect(cycles[[i]], cycles[[j]]))
union <- length(union(cycles[[i]], cycles[[j]]))
intersection / union
})
mean(similarities, na.rm = TRUE)
}
c <- list(
c(1, 2, 3),
c(2, 3, 4),
c(3, 4, 5)
)
calculate_jaccard_similarity(c)
debugonce(calculate_jaccard_similarity)
calculate_jaccard_similarity(c)
View(combinations)
View(cycles)
?combn
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
# Handle cases where cycles length is 0 or 1
if (length(cycles) < 2) {
return(NA)  # or return a default value, depending on your needs
}
total_similarity <- 0
count <- 0
# Create a data frame from the cycles list
cycles_df <- tibble::tibble(cycle = cycles)
# Calculate pairwise Jaccard similarity using dplyr and purrr
cycles_df <- cycles_df %>%
mutate(index = row_number()) %>%
cross_join(cycles_df, by = character()) %>%
filter(index.x < index.y) %>%
mutate(intersection = map2_int(cycle.x, cycle.y, ~ length(intersect(.x, .y))),
union = map2_int(cycle.x, cycle.y, ~ length(union(.x, .y))),
similarity = intersection / union)
total_similarity <- sum(cycles_df$similarity)
count <- nrow(cycles_df)
return(total_similarity / count)
}
c <- list(
c(1, 2, 3),
c(2, 3, 4),
c(3, 4, 5)
)
calculate_jaccard_similarity(c)
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
if (length(cycles) <= 1) {
return(NA) # Return NA if there are 0 or 1 cycles
}
combinations <- combn(seq_along(cycles), 2, simplify = FALSE)
similarities <- map_dbl(combinations, ~ {
i <- .x[1]
j <- .x[2]
intersection <- length(intersect(cycles[[i]], cycles[[j]]))
union <- length(union(cycles[[i]], cycles[[j]]))
intersection / union
})
mean(similarities, na.rm = TRUE)
}
c
seq_along(c)
vcombn(seq_along(c), 2, simplify = FALSE)
combn(seq_along(c), 2, simplify = FALSE)
combn(seq_along(c), 2)
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
if (length(cycles) <= 1) {
return(NA) # Return NA if there are 0 or 1 cycles
}
combinations <- combn(seq_along(cycles), 2, simplify = FALSE)
similarities <- map_dbl(combinations, ~ {
i <- .x[1]
j <- .x[2]
intersection <- length(intersect(cycles[[i]], cycles[[j]]))
union <- length(union(cycles[[i]], cycles[[j]]))
intersection / union
})
mean(similarities, na.rm = TRUE)
}
calculate_jaccard_similarity(c)
c[[1]]
length(intersect(cycles[[1]], cycles[[2]]))
length(intersect(cycles[[1]], cycles[[3]]))
combinations <- combn(seq_along(c), 2, simplify = FALSE)
i <- combinations[1]
j <- combinations[2]
i
str(combinations)
combinations
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
if (length(cycles) <= 1) {
return(NA) # Return NA if there are 0 or 1 cycles
}
combinations <- combn(seq_along(cycles), 2, simplify = FALSE)
similarities <- map_dbl(combinations, ~ {
i <- .x[1]
j <- .x[2]
intersection <- length(base::intersect(cycles[[i]], cycles[[j]]))
union <- length(base::union(cycles[[i]], cycles[[j]]))
intersection / union
})
mean(similarities, na.rm = TRUE)
}
calculate_jaccard_similarity(c)
calculate_jaccard_similarity(cycles[[2]])
cycles
loop_info
common_cycle <- loop_info |>
# extract node number without the first node that repeats
purrr::map(\(x) str_extract_all(x$id, "\\d", simplify = T)[,-1] |>
table(exclude = "") |> as.data.frame() %>%
dplyr::mutate(n_loop =  nrow(x),
# normalized overlap score1 = sum(cycle)count^2) / node_num * (cycle_num)^2
common_score = sum((Freq)^2) ,
nos1 = common_score / (9 * (n_loop)^2),
# normalized overlap score 2 = sum(cycle_count - 1) / node_num * (cycle_num)
nos2 = sum(Freq - 1) / (9 * n_loop))
)
View(cycles)
jaccard <- cycles |>
purrr::map(~calculate_jaccard_similarity)
View(jaccard)
jaccard <- cycles |>
purrr::map(~.x |> calculate_jaccard_similarity)
jaccard <- cycles |>
purrr::map(~.x |> calculate_jaccard_similarity())
View(jaccard)
jaccard[[1]]
jacaard |>
list_rbind()
jaccard |>
list_rbind()
a <- jaccard |>
list_rbind()
rlang::last_trace()
jaccard <- cycles |>
purrr::map_dbl(~.x |> calculate_jaccard_similarity())
a <- jaccard |>
mutate(replace_na(x,0))
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
if (length(cycles) <= 1) {
return(0) # Return zero if there are 0 or 1 cycles
}
combinations <- utils::combn(seq_along(cycles), 2, simplify = FALSE)
similarities <- purrr::map_dbl(combinations, ~ {
i <- .x[1]
j <- .x[2]
intersection <- length(base::intersect(cycles[[i]], cycles[[j]]))
union <- length(base::union(cycles[[i]], cycles[[j]]))
intersection / union
})
mean(similarities, na.rm = TRUE)
}
jaccard <- cycles |>
purrr::map_dbl(~.x |> calculate_jaccard_similarity())
common_cycle <- loop_info |>
# extract node number without the first node that repeats
purrr::map(\(x) str_extract_all(x$id, "\\d", simplify = T)[,-1] |>
table(exclude = "") |> as.data.frame() %>%
dplyr::mutate(n_loop =  nrow(x),
# normalized overlap score1 = sum(cycle)count^2) / node_num * (cycle_num)^2
common_score = sum((Freq)^2) ,
nos1 = common_score / (9 * (n_loop)^2),
# normalized overlap score 2 = sum(cycle_count - 1) / node_num * (cycle_num)
nos2 = sum(Freq - 1) / (9 * n_loop))
)
nos1 <- common_cycle |> purrr::map_dbl(list("nos1", 1), .default = 0)
nos2 <- common_cycle |> purrr::map_dbl(list("nos2", 1), .default = 0)
# add it to the result
# comb_res <- rbind(original_res, res) |>
# mutate(nloop = rep(c(nloop_A, loop_numbers), each =3)) |>
comb_res <- rbind(original_res2, res2) |>
dplyr::mutate(nloop = rep(loop_numbers, each =5),
nos1 = rep(nos1, each = 5),
nos2 = rep(nos2, each = 5),
jaccard = rep(jaccard, each = 5)) |>
pivot_longer(!c(nloop, mat, common_score), names_to = "sim", values_to = "value") |>
dplyr::mutate(matr = stringr::str_extract_all(mat, "\\d+", simplify = T)[,1],
t = factor(stringr::str_extract_all(mat, "\\d+", simplify = T)[,2], levels = c("400", "800", "1200", "1600", "2000")),
sim = stringr::str_extract_all(sim, "\\d+", simplify = T),
# if loop number is higher than 20, then 20
nloop = ifelse(nloop >= 20, 20, nloop)
# group = case_when(
#   common_score == 0 ~ "0",
#   common_score <2 ~ "[1,2)",
#   common_score <3 ~ "[2,3)",
#   common_score <4 ~ "[3,4)",
#   common_score <5 ~ "[4,5)",
#   common_score <7 ~ "[5,6.5]")
)
comb_avg_res <- rbind(ori_avg_res, avg_res) |>
dplyr::mutate(nloop = rep(loop_numbers, each =5),
nos1 = rep(nos1, each = 5),
nos2 = rep(nos2, each = 5),
jaccard = rep(jaccard, each = 5)) |>
# pivot_longer(!c(nloop, mat, common_score), names_to = "sim", values_to = "value") |>
dplyr::mutate(matr = stringr::str_extract_all(mat, "\\d+", simplify = T)[,1],
t = factor(stringr::str_extract_all(mat, "\\d+", simplify = T)[,2], levels = c("400", "800", "1200", "1600", "2000")),
# if loop number is higher than 20, then 20
nloop = ifelse(nloop >= 20, 20, nloop),
group = case_when(
nos1 < 0.05 ~ "<0.05",
nos1 <0.10 ~ "<0.10",
nos1 <0.15 ~ "<0.15",
nos1 <0.20 ~ "<0.20",
nos1 >= 0.20 ~ "0.20+",
)
)
# boxplot _ number feedback loop
comb_avg_res |> filter(t==2000) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = jaccard,
y = avg, col = jaccard)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
hist(jaccard)
# boxplot _ number feedback loop
comb_avg_res |> filter(t==2000) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = nos2,
y = avg, col = nos2)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
# boxplot _ number feedback loop
comb_avg_res |> filter(t==400) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = nos2,
y = avg, col = nos2)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
# boxplot _ number feedback loop
comb_avg_res |> filter(t==1200) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = nos2,
y = avg, col = nos2)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
# boxplot _ number feedback loop
comb_avg_res |> filter(t==1200) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = nos1,
y = avg, col = nos1)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
# boxplot _ number feedback loop
comb_avg_res |> filter(t==2000) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = nos1,
y = avg, col = nos1)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
# boxplot _ number feedback loop
comb_avg_res |> filter(t==800) |>
# ggplot(aes(x = factor(nloop),
#              y = avg, fill = common_score, col = common_score)) +
ggplot(aes(x = nos1,
y = avg, col = nos1)) +
geom_point(
size = 1,
alpha = 0.2) +
# geom_boxplot(width = .2,
#              outlier.alpha = 0.1,
#              #outlier.size = 0.5,
#              outlier.size = 0,
#              alpha = 0.2,
# position = position_dodge(width = 0.5))  +
geom_flat_violin(position = position_nudge(x = .2),
alpha = 0.4,
adjust = 1.1,
trim = T) +
facet_wrap(~factor(nloop))
warnings()
2&17
2^17
help("remove.edge.attribute")
??remove.edge.attribute
View(cycles)
jaccard
hist(jaccard)
version()
library(dplyr)
library(ggplot2)
library(ggridges) # geom_ridges
library(PupillometryR) # geom_flat_violin
library(ggthemes)
library(ggpubr)
library(plot3D) # for 3d regression plane
library(ggExtra) # for adding marginal distributions
library(grid) # for adding the overarching facet title
library(gtable) # for adding the overarching facet title
source("code/libraries.R")
## source necessary functions
source("code/euler_stochastic2.R")
source("code/mod_specification.R")
source("code/gen_network.R")
res16384 <- readRDS("data/res_16384.rds")
# "mat order" has to be manually edited (previously error)
res32768 <- readRDS("data/res_32768.rds") |> dplyr::mutate(mat = paste0(rep(16385:32768, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res49152 <- readRDS("data/res_49152.rds") |> dplyr::mutate(mat = paste0(rep(32769:49152, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res65536 <- readRDS("data/res_65536.rds") |> dplyr::mutate(mat = paste0(rep(49153:65536, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res81920 <- readRDS("data/res_81920.rds") |> dplyr::mutate(mat = paste0(rep(65537:81920, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res98304 <- readRDS("data/res_98304.rds") |> dplyr::mutate(mat = paste0(rep(81921:98304, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res114688 <- readRDS("data/res_114688.rds") |> dplyr::mutate(mat = paste0(rep(98305:114688, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res131071 <- readRDS("data/res_131071.rds") |> dplyr::mutate(mat = paste0(rep(114689:131071, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
res2 <- res16384 |> bind_rows(res32768, res49152, res65536, res81920, res98304, res114688, res131071)
rm(res16384, res32768, res49152, res65536, res81920, res98304, res114688, res131071)
avg_res <- res2 |>
rowwise() |>
mutate(avg = mean(total...1:total...50)) |>
select(avg, mat) |>
ungroup() # cancel rowwise
## aggregate symptom level
n_sims <- 50
# get all networks
# Main execution
## weigthed adjacency matrix
A <- matrix(c( .30, 0, 0, 0, 0, 0, 0, 0, 0,
.33, .30, .14, .15, 0, .13, 0, 0, .15,
0,  0, .30, .22, .23, 0, 0, 0, 0,
.21, 0, 0, .30, 0, 0, 0.12, 0, 0,
0, 0, 0, .17, .30, 0, 0, 0, 0,
0, .13, 0, 0, .15, .30, .2, .15, .22,
0, 0, 0, 0, 0, 0, .30, .17, 0,
0, 0, 0, 0, 0, 0, 0, .30, 0,
0, 0, 0, 0, 0, 0, 0, .3, 0.30), 9, 9, byrow = T)
rownames(A) <- colnames(A) <- c("anh", "sad", "slp", "ene", "app", "glt", "con", "mot", "sui")
modifiable_edges <- list(c(2,1), c(2,3), c(2,4), c(2,6), c(2,9), c(3,4), c(3,5), c(4,1), c(4,7), c(5,4), c(6,2), c(6,5), c(6,7), c(6,8), c(6,9), c(7,8), c(9,8))
all_networks <- generate_configurations(A, modifiable_edges)
## define model specifics: choose the scenario and initial value for symptoms
mod <- mod_spec(scenario = "base", init_val = 0.01, mat = A)
## define "f"
f <- function(x) x^2
## original params
parms1 <- c(mod$Beta_bistable, mod$delta)
## params given shock (beta: increases)
parms2 <- c(mod$Beta_sick, mod$delta)
## define dt and the number of time steps:
deltaT <- .1 # dt
timelength <- 2000 # length of simulation
n_steps <- as.integer(timelength / deltaT) # must be a number greater than 1
## specify the magnitude of noise and specifics of shock
D_stoeq1 <- 0.01  # before shock
# t_shock <- 1000 # time that shock begins
t_shock <- 50 # time that shock begins
shock_duration <- 300 # shock duration time points
# shock period
shock_period <- data.frame(time = 0:timelength) |>
mutate(shock = ifelse(time >= t_shock & time <= t_shock + shock_duration, TRUE, FALSE))
## Explicitly specifying number of workers
## (default is parallelly::availableCores())
plan(multicore)
# 2nd simulation with diff A mat
original_res2 <- purrr::map(1:n_sims, ~ euler_stochastic2(
Amat = mod$A,
deterministic_rate = mod$dif_eq,
stochastic_rate = mod$sto_eq,
initial_condition = mod$initial_values,
parameters1 = parms1,
parameters2 = parms2,
deltaT = deltaT,
timelength = timelength,
D1 = D_stoeq1,
shock = TRUE,
t_shock = t_shock,
duration = shock_duration)  |>
# due to tiny differences in the underlying floating point representation of the numbers in R
dplyr::filter(round(t,1) == 400.0 |round(t,1) == 800.0 |round(t,1) == 1200.0 |round(t,1) == 1600.0 | round(t,1) == 1999.9) |>
dplyr::mutate(total = rowSums(pick(S_anh:S_sui)), .keep = "none")
) |>
purrr::list_cbind() |>
dplyr::mutate(mat = paste0(rep(0, each = 5),"-", c(400, 800, 1200, 1600, 2000)))
ori_avg_res <- original_res2 |>
rowwise() |>
mutate(avg = mean(total...1:total...50)) |>
select(avg, mat) |>
ungroup() # cancel rowwise
# extract all networks
all_networks <- generate_configurations(A, modifiable_edges)
all_networks <- append(list(A), all_networks)
# compute spectral radius
spec_rad <- lapply(all_networks, sparsevar::spectralRadius) |> unlist()
# get the number of loops
loop_numbers <- c()
for (i in 1:length(all_networks)){
loop_numbers[i] <- find_loops(create_adjacency_list(all_networks[[i]]), all_networks[[i]]) |> length()
}
loop_numbers <- loop_numbers - 9
# Function to calculate Jaccard Similarity Index
calculate_jaccard_similarity <- function(cycles) {
if (length(cycles) <= 1) {
return(0) # Return zero if there are 0 or 1 cycles
}
combinations <- utils::combn(seq_along(cycles), 2, simplify = FALSE)
similarities <- purrr::map_dbl(combinations, ~ {
i <- .x[1]
j <- .x[2]
intersection <- length(base::intersect(cycles[[i]], cycles[[j]]))
union <- length(base::union(cycles[[i]], cycles[[j]]))
intersection / union
})
mean(similarities, na.rm = TRUE)
}
### common nodes in cycle
# get the number of loops
loop_info <- all_networks |>
purrr::map(\(x) find_loops(create_adjacency_list(x), x) |>
purrr::list_rbind(names_to = "id") |>
filter(loop_length != 1) )
